# preLLM Execution Trace

> **Query**: `Zdeployuj apkÄ™ na prod`
> **Timestamp**: 2026-02-16 10:31:22
> **Total duration**: 10096ms

## Configuration

| Parameter | Value |
|---|---|
| `small_llm` | `ollama/qwen:7b` |
| `large_llm` | `openrouter/google/gemini-3-flash-preview` |
| `strategy` | `classify` |

## Decision Path

### Step 1: Configuration âœ…

Resolved models, strategy, and pipeline parameters.

- **Type**: `config`
- **Status**: ok

<details>
<summary>Outputs</summary>

```json
{
  "small_llm": "ollama/qwen:7b",
  "large_llm": "openrouter/google/gemini-3-flash-preview",
  "strategy": "classify",
  "config_path": null,
  "user_context": null
}
```
</details>

---

### Step 2: Pipeline: classify âœ…

llm step in 'classify' pipeline

- **Type**: `llm_call`
- **Status**: ok

<details>
<summary>Outputs</summary>

```json
{
  "classification": {
    "intent": "deploy",
    "confidence": 0.9,
    "domain": "mobile"
  }
}
```
</details>

---

### Step 3: Pipeline: match_rule âœ…

algo step in 'classify' pipeline

- **Type**: `pipeline_step`
- **Status**: ok

<details>
<summary>Outputs</summary>

```json
{
  "matched_rule": {}
}
```
</details>

---

### Step 4: Pipeline: enrich_if_needed â­ï¸

llm step in 'classify' pipeline

- **Type**: `llm_call`
- **Status**: skipped

<details>
<summary>Outputs</summary>

```json
{
  "enriched_query": null
}
```
</details>

---

### Step 5: PreprocessorAgent.preprocess() âœ…

Small LLM (ollama/qwen:7b) preprocessed query using 'classify' strategy.

- **Type**: `agent`
- **Duration**: 3254ms
- **Status**: ok

<details>
<summary>Inputs</summary>

```json
{
  "query": "Zdeployuj apkÄ™ na prod",
  "pipeline": "classify",
  "user_context": {}
}
```
</details>

<details>
<summary>Outputs</summary>

```json
{
  "executor_input": "Zdeployuj apkÄ™ na prod"
}
```
</details>

---

### Step 6: ExecutorAgent.execute() âœ…

Large LLM (openrouter/google/gemini-3-flash-preview) generated final response.

- **Type**: `llm_call`
- **Duration**: 6830ms
- **Status**: ok

<details>
<summary>Inputs</summary>

```json
{
  "executor_input": "Zdeployuj apkÄ™ na prod"
}
```
</details>

<details>
<summary>Outputs</summary>

```json
{
  "content_preview": "Aby poprawnie â€zdeployowaÄ‡ apkÄ™ na prodâ€, muszÄ™ wiedzieÄ‡, z czym mamy do czynienia. PoniewaÅ¼ nie podaÅ‚eÅ› szczegÃ³Å‚Ã³w, przygotowaÅ‚em **checklistÄ™ i scenariusze** dla najpopularniejszych technologii.\n\nWybierz swojÄ… drogÄ™:\n\n---\n\n### ğŸŸ¢ Scenariusz A: Prosta aplikacja Frontend (React, Vue, HTML)\nJeÅ›li masz",
  "model": "openrouter/google/gemini-3-flash-preview"
}
```
</details>

- **retries**: `0`

---

## Result

**Response** (2466 chars):

```
Aby poprawnie â€zdeployowaÄ‡ apkÄ™ na prodâ€, muszÄ™ wiedzieÄ‡, z czym mamy do czynienia. PoniewaÅ¼ nie podaÅ‚eÅ› szczegÃ³Å‚Ã³w, przygotowaÅ‚em **checklistÄ™ i scenariusze** dla najpopularniejszych technologii.

Wybierz swojÄ… drogÄ™:

---

### ğŸŸ¢ Scenariusz A: Prosta aplikacja Frontend (React, Vue, HTML)
JeÅ›li masz statyczne pliki, najlepsze opcje to **Vercel, Netlify** lub **GitHub Pages**.

1.  **Vercel/Netlify:**
    *   PoÅ‚Ä…cz repozytorium GitHub.
    *   Wybierz folder (np. `dist` lub `build`).
    *   Kli...
```

- **model_used**: `openrouter/google/gemini-3-flash-preview`
- **small_model_used**: `ollama/qwen:7b`
- **retries**: `0`
- **strategy**: `classify`
- **classification**: `{'intent': 'deploy', 'confidence': 0.9, 'domain': 'mobile'}`

## Summary

| # | Step | Type | Duration | Status |
|---|---|---|---|---|
| 1 | Configuration | `config` | â€” | âœ… ok |
| 2 | Pipeline: classify | `llm_call` | â€” | âœ… ok |
| 3 | Pipeline: match_rule | `pipeline_step` | â€” | âœ… ok |
| 4 | Pipeline: enrich_if_needed | `llm_call` | â€” | â­ï¸ skipped |
| 5 | PreprocessorAgent.preprocess() | `agent` | 3254ms | âœ… ok |
| 6 | ExecutorAgent.execute() | `llm_call` | 6830ms | âœ… ok |

**Total**: 10096ms
